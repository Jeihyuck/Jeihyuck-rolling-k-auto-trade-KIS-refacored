from datetime import datetime, timedelta
import numpy as np
import pandas as pd
import FinanceDataReader as fdr
from pykrx.stock import get_market_cap_by_ticker, get_nearest_business_day_in_a_week
import logging

from .simulate_with_k_and_get_metrics import simulate_with_k_and_get_metrics

logger = logging.getLogger(__name__)


def get_kosdaq_top_50(date_str: str | None = None):
    """
    pykrx ì‹œê°€ì´ì•¡ + FDR ì¢…ëª©ëª…ì„ ë³‘í•©í•´ KOSDAQ ì‹œì´ ìƒìœ„ 50ê°œë¥¼ ë°˜í™˜
    â”€ ëª¨ë“  ë‹¨ê³„ì—ì„œ ì»¬ëŸ¼Â·í–‰ ì¡´ì¬ ì—¬ë¶€ë¥¼ ê²€ì¦í•˜ì—¬ KeyError ì¬ë°œì„ ë§‰ëŠ”ë‹¤.
    """
    try:
        # â”€â”€ 0. ë‚ ì§œ ë³´ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        target = (
            datetime.today()
            if date_str is None
            else datetime.strptime(date_str, "%Y-%m-%d")
        )
        from_date = get_nearest_business_day_in_a_week(target.strftime("%Y%m%d"))
        logger.info(f"ğŸ“… pykrx ì‹œì´ ì¡°íšŒì¼ â†’ {from_date}")

        # â”€â”€ 1. pykrx ì‹œê°€ì´ì•¡ ì¡°íšŒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        mktcap_df = get_market_cap_by_ticker(from_date, market="KOSDAQ")
        if mktcap_df.empty:
            logger.warning("âš ï¸  pykrx ì‹œì´ DFê°€ ë¹„ì—ˆìŠµë‹ˆë‹¤ â†’ ì¢…ë£Œ")
            return pd.DataFrame()

        # ì¸ë±ìŠ¤(í‹°ì»¤) â†’ ì»¬ëŸ¼ ì „í™˜
        mktcap_df = mktcap_df.reset_index()

        # ì‹œê°€ì´ì•¡Â·í‹°ì»¤ ì»¬ëŸ¼ëª… íƒìƒ‰ (ê³µë°±Â·ê´„í˜¸ ëŒ€ë¹„)
        cols = mktcap_df.columns.tolist()
        capcol = next((c for c in cols if "ì‹œê°€ì´ì•¡" in c.replace(" ", "")), None)
        ticcol = next((c for c in cols if "í‹°ì»¤" in c.replace(" ", "")), None)
        if capcol is None or ticcol is None:
            logger.error(f"âŒ  í•„ìˆ˜ì»¬ëŸ¼ ëˆ„ë½ cap={capcol}, tic={ticcol}")
            return pd.DataFrame()

        # í‘œì¤€ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë¦¬ë„¤ì„ + ì½”ë“œ 6ìë¦¬ ë§ì¶¤
        mktcap_df = mktcap_df.rename(columns={capcol: "Marcap", ticcol: "Code"})
        mktcap_df["Code"] = mktcap_df["Code"].astype(str).str.zfill(6)

        logger.info(
            f"[DEBUG] pykrx after rename â†’ {mktcap_df[['Code', 'Marcap']].head()}"
        )

        # â”€â”€ 2. FDR ì¢…ëª© ê¸°ë³¸ì •ë³´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        fdr_df = fdr.StockListing("KOSDAQ").rename(
            columns={"Symbol": "Code", "Name": "Name"}
        )
        fdr_df["Code"] = fdr_df["Code"].astype(str).str.zfill(6)

        # â”€â”€ 3. ë³‘í•© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        merged = pd.merge(fdr_df, mktcap_df[["Code", "Marcap"]], on="Code", how="inner")
        logger.info(f"[DEBUG] merged.columns â†’ {merged.columns.tolist()}")
        logger.info(f"[DEBUG] merged.shape   â†’ {merged.shape}")

        # ë³‘í•© í›„ ì»¬ëŸ¼ëª…ì´ Marcap_x / Marcap_y ì¼ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ í‘œì¤€í™”
        if "Marcap" not in merged.columns:
            if "Marcap_x" in merged.columns:
                merged = merged.rename(columns={"Marcap_x": "Marcap"})
            elif "Marcap_y" in merged.columns:
                merged = merged.rename(columns={"Marcap_y": "Marcap"})

        if "Marcap" not in merged.columns:
            logger.error("âŒ  ë³‘í•© í›„ì—ë„ 'Marcap' ì»¬ëŸ¼ ì—†ìŒ â†’ ì¢…ë£Œ")
            return pd.DataFrame()

        # â”€â”€ 4. NaN ì œê±°Â·ìƒìœ„ 50 ì¶”ì¶œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        merged = merged.dropna(subset=["Marcap"])
        top50 = merged.sort_values("Marcap", ascending=False).head(50)

        if top50.empty:
            logger.warning("âš ï¸  Top50 ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŒ â†’ ì¢…ë£Œ")
            return pd.DataFrame()

        logger.info(f"âœ…  ì‹œì´ Top50 ì¶”ì¶œ ì™„ë£Œ â†’ {len(top50)} ì¢…ëª©")
        logger.info(f"[ìƒ˜í”Œ]\n{top50[['Code', 'Name', 'Marcap']].head()}")

        return top50[["Code", "Name", "Marcap"]]

    except Exception:
        logger.exception("âŒ  get_kosdaq_top_50 ì˜ˆì™¸:")
        return pd.DataFrame()


def simulate_k_range_for(stock_code, price_data, k_range=np.arange(0.1, 1.0, 0.1)):
    results = []
    for k in k_range:
        metrics = simulate_with_k_and_get_metrics(stock_code, k, price_data)
        metrics["k"] = k
        metrics["sharpe"] = round(
            (metrics["avg_return_pct"] / 100) / (0.01 + metrics["mdd_pct"] / 100), 2
        )
        results.append(metrics)
    return results


import logging
from datetime import timedelta
import FinanceDataReader as fdr

logger = logging.getLogger(__name__)

def get_price_data_segments(code: str, base_date: datetime.date) -> dict[str, list[dict]]:
    """
    ì¢…ëª© ì½”ë“œ(code)ì™€ ê¸°ì¤€ì¼(base_date)ì— ëŒ€í•´
    ê³¼ê±° 1ë…„, 90ì¼, 30ì¼ ê°€ê²© ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ì—¬
    'year', 'quarter', 'month'ë¡œ êµ¬ë¶„í•´ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        # ì¡°íšŒ ê¸°ê°„ ì„¤ì •: ê³¼ê±° 400ì¼ì¹˜ë¶€í„° ë¦¬ë°¸ëŸ°ìŠ¤ ì „ë‚ ê¹Œì§€
        start_date = base_date - timedelta(days=400)
        end_date = base_date - timedelta(days=1)
        logger.info(f"[DEBUG] ğŸ“¦ Fetching {code} from {start_date} to {end_date}")

        df = fdr.DataReader(code, start=start_date, end=end_date)
        logger.info(f"[DEBUG] ğŸ“Š DataReader returned {df.shape} rows for {code}")

        # í•„ìˆ˜ ì»¬ëŸ¼ë§Œ ë‚¨ê¸°ê³  ê²°ì¸¡ì¹˜ ì œê±°
        df = df.dropna(subset=["Open", "High", "Low", "Close"])
        df = df.rename(columns={
            "Open": "open",
            "High": "high",
            "Low": "low",
            "Close": "close"
        })

        # ë‚ ì§œ ì»¬ëŸ¼ ìƒì„± ë° ì •ë¦¬
        df = df.reset_index()
        df["date"] = df["Date"].dt.date
        df = df[["date", "open", "high", "low", "close"]]
        df = df.sort_values("date")

        # êµ¬ê°„ë³„ë¡œ ë¶„ë¦¬
        price_data = {
            "year": df[df["date"] >= base_date - timedelta(days=365)].to_dict(orient="records"),
            "quarter": df[df["date"] >= base_date - timedelta(days=90)].to_dict(orient="records"),
            "month": df[df["date"] >= base_date - timedelta(days=30)].to_dict(orient="records"),
        }
        logger.info(
            f"[DEBUG] âœ… Segments for {code}: "
            f"year={len(price_data['year'])}, "
            f"quarter={len(price_data['quarter'])}, "
            f"month={len(price_data['month'])}"
        )
    except Exception as e:
        logger.exception(f"[ERROR] âŒ Failed to fetch data for {code}: {e}")
        price_data = {"year": [], "quarter": [], "month": []}

    return price_data



# --------------------------------------------------------------------
# Rolling-K ë³€ë™ì„±-ëŒíŒŒ : ì½”ìŠ¤ë‹¥ Top50 ì¢…ëª©ë³„ Best-K ì„ ì • + í•„í„°ë§
# --------------------------------------------------------------------
def get_best_k_for_kosdaq_50(rebalance_date_str: str) -> list[dict]:
    """
    â— ì…ë ¥  : ë¦¬ë°¸ëŸ°ìŠ¤ ê¸°ì¤€ì¼(YYYY-MM-DD)
    â— ì¶œë ¥  : ì¡°ê±´ í†µê³¼ ì¢…ëª© ë¦¬ìŠ¤íŠ¸   list[dict]
              â”” dict ì˜ˆì‹œ
                 {
                     "code"            : "091990",
                     "name"            : "ì…€íŠ¸ë¦¬ì˜¨í—¬ìŠ¤ì¼€ì–´",
                     "best_k"          : 0.4,
                     "avg_return_pct"  : 8.7,
                     "win_rate_pct"    : 65.0,
                     "mdd_pct"         : 7.2,
                     "trades"          : 12,
                     "cumulative_return_pct": 29.5,
                     "avg_holding_days": 4.3,
                     "sharpe_y"        : 1.12,
                     "sharpe_q"        : 1.35,
                     "sharpe_m"        : 1.77
                 }
    """
    rebalance_date = datetime.strptime(rebalance_date_str, "%Y-%m-%d").date()
    today = datetime.today().date()

    # 1) ì‹œê°€ì´ì•¡ Top50 í™•ë³´
    top50_df = get_kosdaq_top_50(rebalance_date_str)
    if top50_df.empty:
        logger.warning("[WARN] get_kosdaq_top_50 ê²°ê³¼ ì—†ìŒ â†’ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜")
        return []

    # 2) ì¢…ëª©ë³„ ì‹œë®¬ë ˆì´ì…˜
    result_map: dict[str, dict] = {}

    for _, stock in top50_df.iterrows():
        code = stock["Code"]
        name = stock["Name"]

        try:
            # ê°€ê²© ë°ì´í„° 1ë…„ì¹˜ ë‹¤ìš´ë¡œë“œ & ì„¸ê·¸ë¨¼íŠ¸ ë¶„í• 
            price_segments = get_price_data_segments(code, rebalance_date)
            if not price_segments["month"]:
                logger.warning(f"[SKIP] {name}({code}) ì „ì›” ë°ì´í„° ì—†ìŒ")
                continue

            # Kê°’ ë²”ìœ„ ì‹œë®¬
            y_metrics = simulate_k_range_for(code, price_segments["year"])
            q_metrics = simulate_k_range_for(code, price_segments["quarter"])
            m_metrics = simulate_k_range_for(code, price_segments["month"])

            best_k = get_best_k_meta(y_metrics, q_metrics, m_metrics)

            # ë¦¬ë°¸ëŸ°ìŠ¤ ê¸°ì¤€ì¼ì´ ê³¼ê±°ë©´ ë‹¤ì‹œ ì „ì›” ì‹¤ì  ê²€ì¦
            avg_return = win_rate = mdd = trades = cum_ret = hold_days = 0
            if rebalance_date < today:
                month_perf = simulate_with_k_and_get_metrics(
                    code, best_k, price_segments["month"]
                )
                avg_return = month_perf["avg_return_pct"]
                win_rate = month_perf["win_rate_pct"]
                mdd = month_perf["mdd_pct"]
                trades = month_perf.get("trades", 0)
                cum_ret = month_perf.get("cumulative_return_pct", avg_return)
                hold_days = month_perf.get("avg_holding_days", 1)

            logger.info(
                f"[SIM] {name}({code}) R={avg_return:.1f}%  "
                f"W={win_rate:.1f}%  MDD={mdd:.1f}%  K={best_k}"
            )

            # 3) í•„í„°ë§
            #if avg_return > 5 and win_rate > 60 and mdd < 10:
            if avg_return > 1 and win_rate > 20 and mdd < 30:
                result_map[code] = {
                    "code": code,
                    "name": name,
                    "best_k": best_k,
                    "avg_return_pct": round(avg_return, 2),
                    "win_rate_pct": round(win_rate, 1),
                    "mdd_pct": round(mdd, 1),
                    "trades": trades,
                    "cumulative_return_pct": round(cum_ret, 2),
                    "avg_holding_days": round(hold_days, 1),
                    "sharpe_y": max((m["sharpe"] for m in y_metrics), default=0),
                    "sharpe_q": max((m["sharpe"] for m in q_metrics), default=0),
                    "sharpe_m": max((m["sharpe"] for m in m_metrics), default=0),
                }

        except Exception as e:
            logger.exception(f"[ERR] {name}({code}) ì‹œë®¬ ì‹¤íŒ¨: {e}")

    # 4) list[dict] ë¡œ ë°˜í™˜  (rebalance_watchlist.py ê°€ dict.get() ì‚¬ìš© ê°€ëŠ¥)
    logger.info(f"ğŸ“Š í•„í„° í†µê³¼ ì¢…ëª© = {len(result_map)}ê°œ")
    return list(result_map.values())


def get_best_k_meta(year_metrics, quarter_metrics, month_metrics):
    """
    Sharpe ì ìˆ˜ ê¸°ë°˜ Kê°’ ì„ íƒ
    - ì—°: 1.0 ê°€ì¤‘ì¹˜
    - ë¶„ê¸°: 1.5
    - ì›”: 2.0
    """
    scores = {}

    def update_scores(metrics, weight):
        for m in metrics:
            k = round(m["k"], 2)
            scores.setdefault(k, 0)
            scores[k] += m.get("sharpe", 0) * weight

    update_scores(year_metrics, 1.0)
    update_scores(quarter_metrics, 1.5)
    update_scores(month_metrics, 2.0)

    if not scores:
        return 0.5  # fallback

    best_k = max(scores.items(), key=lambda x: x[1])[0]
    return round(best_k, 2)
